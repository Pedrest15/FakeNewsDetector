# -*- coding: utf-8 -*-
"""TrabalhoPLN_pt1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uPfkGnmWy1kbQIrCL9QqPG0H_6GjWMpE

# Identificação de Fake News utilizando Métricas Simbólicas
**Processamento de Linguagem Natural - Fake.br Corpus**
"""

# Importação de bibliotecas necessárias
!pip install pyphen
!python -m spacy download pt_core_news_sm

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import spacy
import pyphen
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import graphviz

!git clone https://github.com/roneysco/Fake.br-Corpus

"""## Carregamento de Modelos e Ferramentas de Processamento de Texto"""

# Carregar modelo SpaCy em português
nlp = spacy.load("pt_core_news_sm")

# Configurar dicionário para separação silábica (não utilizado neste projeto)
dic = pyphen.Pyphen(lang='pt')

"""## Definição da Função de Extração de Métricas Simbólicas
A função `extrair_metricas` processa o texto e calcula indicadores linguísticos e simbólicos relevantes para a classificação de notícias.

"""

# Função para extrair métricas simbólicas de um texto
def extrair_metricas(texto):

    def extrair_metricas(texto):
      if not isinstance(texto, str) or len(texto.strip()) == 0:
          return pd.Series([np.nan] * 13, index=[
              "%_verbos_modais", "%_termos_certeza", "%_generalizacao", "%_tendencia", "%_quantificadores",
              "%_numeros", "interrogacoes", "media_palavras_sentenca", "n_sentencas", "diversidade_lexica",
              "n_1p_singular", "n_1p_plural", "n_2_3p_plural"
          ])  # Retorna um vetor de NaN para valores inválidos

    doc = nlp(texto)

    # Definir listas de palavras para categorias específicas
    verbos_modais = ["poder", "dever", "precisar", "querer", "ter que", "saber", ]
    termos_certeza = ["sempre", "nunca", "jamais", "todos", "nenhum", "ninguém"]
    termos_generalizacao = ["todos", "qualquer", "cada", "sempre", "nunca"]
    termos_tendencia = ["geralmente", "frequentemente", "normalmente", "tende", "costuma"]
    quantificadores = ["muito", "pouco", "bastante", "tanto", "toda", "todo"]

    tokens = [token.text.lower() for token in doc if not token.is_punct]
    n_tokens = len(tokens)
    if n_tokens == 0:
        n_tokens = 1  # evitar divisão por zero

    # Cálculo das métricas
    modal = sum(token in verbos_modais for token in tokens) / n_tokens
    certeza = sum(token in termos_certeza for token in tokens) / n_tokens
    generalizacao = sum(token in termos_generalizacao for token in tokens) / n_tokens
    tendencia = sum(token in termos_tendencia for token in tokens) / n_tokens
    quantific = sum(token in quantificadores for token in tokens) / n_tokens
    numeros = sum(token.isdigit() for token in tokens) / n_tokens
    interrogacoes = texto.count("?")

    n_sentencas = len(list(doc.sents))
    media_palavras_sentenca = n_tokens / n_sentencas if n_sentencas > 0 else 0
    diversidade_lexica = len(set(tokens)) / n_tokens

    # Contagem de pronomes de diferentes pessoas
    primeira_pessoa_singular = ["eu", "meu", "minha", "me", "mim"]
    primeira_pessoa_plural = ["nós", "nosso", "nossa", "nos", "conosco"]
    segunda_terceira_pessoa_plural = ["vocês", "eles", "elas", "seus", "suas", "deles", "delas"]

    n_1p_singular = sum(token in primeira_pessoa_singular for token in tokens)
    n_1p_plural = sum(token in primeira_pessoa_plural for token in tokens)
    n_2_3p_plural = sum(token in segunda_terceira_pessoa_plural for token in tokens)

    return pd.Series({
        # incerteza
        "%_verbos_modais": modal,
        "%_termos_certeza": certeza,
        "%_generalizacao": generalizacao,
        "%_tendencia": tendencia,
        "%_quantificadores": quantific,
        "%_numeros": numeros,
        "interrogacoes": interrogacoes,
        # quantidade
        "media_palavras_sentenca": media_palavras_sentenca,
        "n_sentencas": n_sentencas,
        # diversidade
        "diversidade_lexica": diversidade_lexica,
        # não imediação
        "n_1p_singular": n_1p_singular,
        "n_1p_plural": n_1p_plural,
        "n_2_3p_plural": n_2_3p_plural
    })

"""## Download e Carregamento do Dataset Fake.br
O corpus de notícias falsas e verdadeiras será baixado diretamente do GitHub se não estiver presente no diretório local.

## Leitura dos Arquivos de Notícias e Criação do DataFrame
Cada notícia será lida e rotulada (1 para fake, 0 para real).
"""

fake_files = os.listdir('/content/Fake.br-Corpus/full_texts/fake')
true_files = os.listdir('/content/Fake.br-Corpus/full_texts/true')

df_fake = pd.DataFrame(columns = ['noticia', 'label'])
df_true = pd.DataFrame(columns = ['noticia', 'label'])

for files in fake_files:
  df_fake.loc[(len(df_fake))] = [open(os.path.join('/content/Fake.br-Corpus/full_texts/fake', files), 'r').read(), 1]

for files in true_files:
  df_true.loc[(len(df_true))] = [open(os.path.join('/content/Fake.br-Corpus/full_texts/true', files), 'r').read(), 0]

# Concatenar e embaralhar o dataset
df = pd.concat([df_fake, df_true]).sample(frac=1, random_state=42).reset_index(drop=True)

"""## Separação do Conjunto de Dados em Treino e Teste"""

from sklearn.model_selection import train_test_split

train, test = train_test_split(df, test_size=0.3, stratify=df["label"], random_state=42)

# Limpar notícias vazias antes
train = train[train["noticia"].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)].copy()
test = test[test["noticia"].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)].copy()

"""## Extração das Métricas Simbólicas
Aplicação da função `extrair_metricas` nos conjuntos de treino e teste.

"""

# Aplicar extração de métricas
metricas_train = train["noticia"].apply(extrair_metricas)
train_metricas = pd.concat([train.reset_index(drop=True), metricas_train.reset_index(drop=True)], axis=1)
#train_metricas = train_metricas.dropna()

metricas_test = test["noticia"].apply(extrair_metricas)
test_metricas = pd.concat([test.reset_index(drop=True), metricas_test.reset_index(drop=True)], axis=1)
#test_metricas = test_metricas.dropna()

"""## Preparação dos Dados para Modelagem
Seleção das variáveis explicativas (features) e do alvo (target).

"""

features = [
    "%_verbos_modais", "%_termos_certeza", "%_generalizacao", "%_tendencia", "%_quantificadores",
    "%_numeros", "interrogacoes", "media_palavras_sentenca", "n_sentencas", "diversidade_lexica",
    "n_1p_singular", "n_1p_plural", "n_2_3p_plural"
]

X_train = train_metricas[features]
y_train = train_metricas["label"]
X_test = test_metricas[features]
y_test = test_metricas["label"]

"""## Treinamento do Modelo de Árvore de Decisão

"""

clf = DecisionTreeClassifier(max_depth=5, random_state=42)
clf.fit(X_train, y_train)

"""## Avaliação do Modelo: Acurácia e Matriz de Confusão

"""

# Avaliar modelo
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"\nAcurácia no conjunto de teste: {acc:.4f}")

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Real", "Fake"])
disp.plot(cmap="Blues")
plt.title("Matriz de Confusão")
plt.show()

"""## Análise de Importância das Métricas Simbólicas

"""

importancias = pd.Series(clf.feature_importances_, index=features)
importancias.sort_values(ascending=True).plot.barh(color="cornflowerblue")
plt.title("Importância das Métricas Simbólicas")
plt.xlabel("Importância")
plt.tight_layout()
plt.show()

"""## Visualização da Árvore de Decisão

"""

plt.figure(figsize=(24, 12))
plot_tree(
    clf,
    feature_names=features,
    class_names=["Real", "Fake"],
    filled=True,
    rounded=True,
    fontsize=12
)
plt.title("Árvore de Decisão Simbólica", fontsize=16)
plt.show()

"""## Metricas separadamente"""

def classificar_incerteza(texto):
    """
    Classifica a notícia como 'Fake' ou 'True' com base em métricas relacionadas à incerteza.
    Inclui verbos modais, termos de certeza, generalização, tendência, quantificadores, números e interrogações.
    """
    metricas = extrair_metricas(texto).to_frame().T
    metricas_incerteza = metricas[[
        "%_verbos_modais", "%_termos_certeza", "%_generalizacao", "%_tendencia",
        "%_quantificadores", "%_numeros", "interrogacoes"
    ]]
    pred = clf.predict(metricas_incerteza)[0]
    return "Fake" if pred == 1 else "True"

def classificar_quantidade(texto):
    """
    Classifica a notícia como 'Fake' ou 'True' com base nas métricas de quantidade.
    Inclui a média de palavras por sentença e o número de sentenças.
    """
    metricas = extrair_metricas(texto).to_frame().T
    metricas_quantidade = metricas[[
        "media_palavras_sentenca", "n_sentencas"
    ]]
    pred = clf.predict(metricas_quantidade)[0]
    return "Fake" if pred == 1 else "True"

def classificar_diversidade(texto):
    """
    Classifica a notícia como 'Fake' ou 'True' com base na diversidade lexical.
    """
    metricas = extrair_metricas(texto).to_frame().T
    metricas_diversidade = metricas[["diversidade_lexica"]]
    pred = clf.predict(metricas_diversidade)[0]
    return "Fake" if pred == 1 else "True"

def classificar_nao_imediacao(texto):
    """
    Classifica a notícia como 'Fake' ou 'True' com base no uso de pronomes de pessoas gramaticais.
    """
    metricas = extrair_metricas(texto).to_frame().T
    metricas_nao_imediacao = metricas[[
        "n_1p_singular", "n_1p_plural", "n_2_3p_plural"
    ]]
    pred = clf.predict(metricas_nao_imediacao)[0]
    return "Fake" if pred == 1 else "True"

"""## Classificação da noticia"""

def classificar_noticia(texto):
    """
    Classifica uma notícia como verdadeira (True) ou falsa (Fake).

    Parâmetros:
    ----------
    texto : str
        Texto da notícia a ser classificada.

    Retorna:
    -------
    str
        "Fake" se a notícia for falsa, "True" se a notícia for verdadeira.
    """
    # Garantir que o texto não esteja vazio
    if not isinstance(texto, str) or len(texto.strip()) == 0:
        return "Texto inválido."

    # Extrair métricas simbólicas
    metricas = extrair_metricas(texto).to_frame().T  # precisa transformar para DataFrame

    # Selecionar as mesmas features usadas no treinamento
    metricas = metricas[features]

    # Fazer a previsão
    pred = clf.predict(metricas)[0]

    return "Fake" if pred == 1 else "True"